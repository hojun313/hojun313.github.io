---
title: 생성형 AI를 활용한 2D 텍스처 기반 3D 하이트맵 생성 연구 요약
date: 2025-10-20
categories:
  - Blog
  - AI
tags:
  - AI
  - 3D
  - 하이트맵
  - U-Net
  - 생성형AI
summary: 2D 텍스처 이미지를 AI가 분석하여, 표면의 3차원 입체 정보를 담은 하이트맵(Heightmap)을 자동으로 생성하는 모델을 개발하는 프로젝트입니다. Image-to-Image 변환 기술인 U-Net 아키텍처와 전이 학습을 활용하여 개발 과정을 주도했습니다.
---
## 1. 프로젝트 개요

본 프로젝트는 2D 텍스처(질감) 이미지를 AI가 분석하여, 표면의 3차원 입체 정보를 담은 하이트맵(Heightmap)을 자동으로 생성하는 모델을 개발하는 것을 목표로 합니다. 게임, 메타버스 등 디지털 콘텐츠의 현실감을 극대화하고, 숙련된 3D 아티스트가 몇 시간씩 수작업으로 진행하던 제작 공정을 획기적으로 단축하는 기술 기반을 마련하고자 했습니다.

**1인 프로젝트**로서 기획부터 데이터 파이프라인 구축, 모델 설계 및 개발, 결과 분석과 회고까지 전 과정을 주도적으로 수행하며 기술과 기획의 간극을 좁히는 경험을 했습니다.

## 2. 문제 정의 및 핵심 해결 전략

고품질 3D 에셋 제작 과정에서, 사실적인 표면 질감을 표현하는 하이트맵 작업은 높은 전문성과 많은 시간을 요구하는 대표적인 병목 구간이었습니다.

이 문제를 해결하기 위해, 아티스트의 창의적인 결과물(텍스처)을 AI가 깊이 있게 이해하고 그에 맞는 기술적 결과물(하이트맵)을 자동으로 생성해주는 **Image-to-Image 변환 기술**에 주목했습니다. 데이터 기반의 자동화 파이프라인을 구축하여 창작의 효율성을 극대화하는 것을 핵심 전략으로 삼았습니다.

## 3. AI 모델 개발 과정

### 가. 데이터 파이프라인 구축 (재료 준비)

모델 학습을 위해 연구에 널리 활용되는 'Stanford-Gelsight' 데이터셋을 활용했습니다. PyTorch 환경에서 모델이 효과적으로 학습할 수 있도록 데이터 파이프라인을 직접 설계했으며, 주요 과정은 다음과 같습니다.

- **데이터 쌍 구성**: 동영상 데이터에서 프레임을 추출하여 (입력 RGB 이미지, 정답 하이트맵) 쌍으로 구성했습니다.
- **데이터 정제**: 학습에 방해가 되는 Gelsight 센서의 마커를 OpenCV의 인페인팅(Inpainting) 기술로 제거했습니다.
- **데이터 전처리**: 모든 이미지를 256x256 픽셀로 리사이즈하고, -1에서 1 사이의 값을 갖도록 정규화하여 학습 효율성을 높였습니다.

### 나. 최적의 아키텍처 설계 (U-Net과 사전 학습 모델의 시너지)

픽셀 단위의 상세한 위치 정보 보존이 중요한 Image-to-Image 변환 문제 해결을 위해, 이에 강점을 가진 **U-Net 아키텍처**를 채택했습니다.

여기서 더 나아가, 제한된 데이터셋으로도 높은 특징 추출 능력을 확보하기 위해 ImageNet으로 사전 학습된 **EfficientNet-B7을 인코더로 활용**하는 전이 학습(Transfer Learning) 전략을 선택했습니다. 이는 밑바닥부터 학습하는 시간과 비용을 절감하고, 검증된 성능을 바탕으로 프로젝트를 효율적으로 진행하기 위한 데이터 기반의 의사결정이었습니다.

### 다. 손실 함수 최적화 (정답에 대한 깊은 고찰)

단순히 수학적 오차만 줄이는 모델은 사람이 보기에 어색하고 흐릿한 결과물을 만들 수 있었습니다. 기계가 아닌 '사람이 보기에 자연스러운 정답'을 만들기 위해, 두 가지 손실 함수를 조합하여 사용했습니다.

1. **L1 손실**: 픽셀 단위의 절대적인 차이를 최소화하여 전체적인 **구조적 유사성**을 확보합니다.
2. **LPIPS 손실**: 딥러닝 모델을 이용해 인간의 **시지각적 유사성**을 측정하여, 수치적으로는 비슷해도 사람이 보기에 다른 느낌을 주는 문제를 보완합니다.

이 두 가지 손실을 조합함으로써 AI가 더 인간의 눈에 자연스러운 결과물을 생성하도록 유도했습니다.

### 라. 다각적 평가 시스템 구축 (성과의 객관적 증명)

'잘 만들어졌다'는 추상적인 기준을 넘어, 모델의 성공과 실패를 객관적으로 분석하기 위해 종합적인 정량 평가 시스템을 직접 구현했습니다.

- **구조적/지각적 유사도**: SSIM (Structural Similarity), LPIPS
- **엣지(Edge) 표현력**: Canny 엣지 맵을 활용한 F1-Score, Precision, Recall 계산
- **통계적 질감 특징**: GLCM(Gray Level Co-occurrence Matrix) 특징 벡터 간의 코사인 유사도 비교

## 4. 결과 분석: 성공과 또 다른 기회의 발견

### 주요 성과

학습에 사용되지 않은 새로운 데이터에 대해, 원본의 통계적 질감 특징을 **99.58% 수준(GLCM Cosine Similarity)으로 재현**하는 고품질 하이트맵 생성에 성공했습니다. 이는 AI가 질감의 전반적인 특징(거칠기, 방향성 등)을 매우 성공적으로 학습했음을 의미하는 객관적인 지표입니다.

### 결과물 시각화

_(왼쪽부터: 입력 텍스처, 정답 하이트맵, AI가 생성한 하이트맵)_

성공 사례 1: PlasticMesh2 전체적인 격자 구조를 성공적으로 재현했습니다.
![PlasticMesh2.png](./블로그%20자료/PlasticMesh2.png)

성공 사례 2: ArtificialGrass 엣지 표현은 다소 뭉개졌지만, 인조잔디 특유의 불규칙하고 뾰족한 질감 특징을 잘 재현했습니다.
![ArtificialGrass.png](./블로그%20자료/ArtificialGrass.png)

### 객관적인 한계 분석 및 교훈

날카로운 경계선을 표현하는 **엣지 표현력(Edge F1-Score: 0.0164)에서는 명확한 한계를 정량적으로 발견**했습니다. 이는 모델이 경계선의 위치는 어렴풋이 감지하지만, 날카롭게 생성하지는 못하고 뭉개는 경향이 있음을 보여줍니다.

저는 이것을 실패가 아닌, **다음 모델 개선을 위한 명확한 방향성을 제시하는 의미 있는 발견**으로 정의했습니다. 이 한계를 극복하기 위해 GAN(Generative Adversarial Network) 도입이나 엣지 강화 손실 함수 추가 등의 구체적인 후속 연구 방향을 도출할 수 있었습니다.

## 5. 프로젝트를 통해 체득한 PM의 관점

이 프로젝트는 단순히 AI 모델을 개발하는 것을 넘어, 성공적인 기술 기반 프로젝트를 이끌기 위해 PM에게 필요한 핵심 역량을 실전적으로 체득하는 소중한 경험이었습니다.

1. **데이터 기반 목표 설정 능력** '사실적인 결과물'이라는 추상적인 목표를 'SSIM 0.9 이상, LPIPS 0.1 이하, GLCM Cosine Sim. 0.99 이상' 등 **구체적인 성공 지표(KPI)로 정의하고 측정**하는 경험을 통해, 데이터에 기반하여 프로젝트의 성공을 관리하는 역량을 길렀습니다.
2. **기술적 리스크 관리 및 현실적 기획 능력** 엣지 표현력 부족과 같은 모델의 한계를 정량적으로 분석하며, AI 기술의 잠재력과 **현실적인 제약을 명확히 파악하는 시각**을 갖췄습니다. 이는 향후 PM으로서 개발 공수를 현실적으로 산정하고 기술적 리스크를 사전에 관리하는 데 큰 자산이 될 것입니다.
3. **개발 프로세스에 대한 깊은 이해와 소통 능력** 데이터 준비부터 모델 설계, 학습, 평가, 분석에 이르는 **AI 개발의 전체 사이클을 직접 수행**하며 기술에 대한 깊이 있는 이해를 갖췄습니다. 이는 개발팀과 같은 언어로 소통하고, 기술적 제약을 고려한 현실적인 기획을 수립하는 데 핵심적인 역량이 될 것이라 확신합니다.